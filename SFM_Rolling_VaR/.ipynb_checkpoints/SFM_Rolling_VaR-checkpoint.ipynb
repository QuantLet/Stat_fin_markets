{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde, norm, cauchy\n",
    "\n",
    "from scipy.stats import t\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from arch import arch_model\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "start = datetime.datetime(2014,7,16)\n",
    "end = datetime.datetime(2020,11,17)\n",
    "#end = datetime.date.today()\n",
    "\n",
    "\n",
    "from pandas_datareader import data as wb  \n",
    "\n",
    "ticker = 'BTC-USD' \n",
    "df = pd.DataFrame()\n",
    "\n",
    "df = wb.DataReader(ticker, data_source='yahoo', start=start, end=end)['Close']\n",
    "\n",
    "log_ret = np.log(1 + df.pct_change())\n",
    "\n",
    "log_ret.replace([np.inf, -np.inf], np.nan, inplace=True) \n",
    "  \n",
    "# Dropping all the rows with nan values \n",
    "log_ret.dropna(inplace=True) \n",
    "  \n",
    "log_returns=np.asarray(log_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# w=window length (trading days)\n",
    "#alpha = the significance level\n",
    "w=500\n",
    "alpha=0.01\n",
    "\n",
    "\n",
    "VaR_empiric=[]\n",
    "VaR_normal=[]\n",
    "VaR_GARCH_n=[]\n",
    "VaR_GARCH_t=[]\n",
    "VaR_t=[]\n",
    "\n",
    "\n",
    "#from numba import autojit\n",
    "#@autojit\n",
    "def Rolling_VaR(log_returns,w,alpha):\n",
    "    iterations=len(log_returns)-w\n",
    "\n",
    "    for i in range(1,iterations):\n",
    "        ret=log_returns[i:(w+i-1)]\n",
    "        q=np.quantile(ret, alpha)\n",
    "   \n",
    "        x=(ret[ret<=q])\n",
    "        y=np.asarray(x)\n",
    "        n=len(y)\n",
    "        \n",
    "        mu=ret.mean()\n",
    "        sigma=ret.std()\n",
    "        v_normal=norm.ppf(alpha)*sigma+mu;\n",
    "\n",
    "        VaR_normal.append(v_normal);\n",
    "        \n",
    "        r = t.fit(ret)\n",
    "        nu=r[0]\n",
    "        v_t = (t.ppf(alpha, nu)*sigma)+mu\n",
    "        VaR_t.append(v_t);\n",
    "        '''\n",
    "        if nu>2:\n",
    "            v_t = -(np.sqrt((nu-2)/nu) * t.ppf(1-alpha, nu)*sigma - mu)\n",
    "            VaR_t.append(v_t);\n",
    "        else:\n",
    "            v_t = -(t.ppf(1-alpha, nu)*sigma - mu)\n",
    "            VaR_t.append(v_t);\n",
    "        '''    \n",
    "        v_empiric=np.quantile(ret,alpha);\n",
    "        VaR_empiric.append(v_empiric);\n",
    "\n",
    "        # define model with Normal residuals\n",
    "        model = arch_model(ret*100, vol='GARCH', p=1, q=1);\n",
    "        # fit model\n",
    "        model_fit = model.fit(disp=0);\n",
    "        # forecast the test set\n",
    "        yhat = model_fit.forecast(horizon=1);\n",
    "        var_n=(0.01*np.sqrt(yhat.variance.values[-1]) * norm.ppf(alpha) +mu)\n",
    "        VaR_GARCH_n.append(var_n);\n",
    "\n",
    "        # define model\n",
    "        model = arch_model(ret*100, vol='GARCH', p=1, q=1,dist='StudentsT');\n",
    "        # fit model\n",
    "        model_fit = model.fit(disp=0);\n",
    "        df=(model_fit.params[4]);\n",
    "        # forecast the test set\n",
    "        yhat = model_fit.forecast(horizon=1);\n",
    "        var_t=(0.01*np.sqrt(yhat.variance.values[-1]) * t.ppf(alpha,df) +mu);\n",
    "        VaR_GARCH_t.append(var_t);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "Rolling_VaR(log_returns,w,alpha)\n",
    "dt = timer() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Created in %f s\" % dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=log_ret[(w+1):len(log_ret)]\n",
    "dates=df_new.index.tolist()\n",
    "\n",
    "\n",
    "VaR_empiric=np.asarray(VaR_empiric)\n",
    "VaR_normal=np.asarray(VaR_normal)\n",
    "VaR_GARCH_n=np.asarray(VaR_GARCH_n)\n",
    "\n",
    "\n",
    "VaR_GARCH_t=np.asarray(VaR_GARCH_t)\n",
    "\n",
    "\n",
    "VaR_t=np.asarray(VaR_t)\n",
    "\n",
    "\n",
    "returns=np.asarray(log_returns[(w+1):len(log_returns)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(20,10) )\n",
    "plt.plot(dates,VaR_empiric, label='VaR Empiric',c='red')\n",
    "plt.plot(dates, VaR_GARCH_n, label='VaR GARCH Gaussian',c='blue')\n",
    "plt.plot(dates,VaR_normal, label='VaR Gaussian',c='green')\n",
    "plt.plot(dates, VaR_GARCH_t, label='VaR GARCH Student',c='lightblue')\n",
    "plt.plot(dates, VaR_t, label='VaR Student',c='brown')\n",
    "plt.plot(dates, returns, label='Log-return',c='black',linewidth=0.2)\n",
    "#plt.plot(VaR_empiric, label='VaR')\n",
    "#plt.plot(VaR_GARCH_n, label='VaR GARCH Gaussian')\n",
    "\n",
    "plt.legend(loc='upper center',bbox_to_anchor=(0.5, -0.07), fancybox=True, shadow=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/BayerSe/VaR-Backtesting/blob/master/backtest.py\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "class Backtest:\n",
    "    def __init__(self, actual, forecast, alpha):\n",
    "        self.index = actual.index\n",
    "        self.actual = actual.values\n",
    "        self.forecast = forecast.values\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def hit_series(self):\n",
    "        return (self.actual < self.forecast) * 1\n",
    "\n",
    "    def number_of_hits(self):\n",
    "        return self.hit_series().sum()\n",
    "\n",
    "    def hit_rate(self):\n",
    "        return self.hit_series().mean()\n",
    "\n",
    "    def expected_hits(self):\n",
    "        return self.actual.size * self.alpha\n",
    "\n",
    "    def duration_series(self):\n",
    "        hit_series = self.hit_series()\n",
    "        hit_series[0] = 1\n",
    "        hit_series[-1] = 1\n",
    "        return np.diff(np.where(hit_series == 1))[0]\n",
    "    \n",
    "    def binomial_test(self):\n",
    "        #Binomial Test\n",
    "        N=len(self.actual)\n",
    "        N_fail=self.hit_series().sum()\n",
    "        z=(N_fail-N*self.alpha)/np.sqrt(N*alpha*(1-self.alpha))\n",
    "   \n",
    "        p_value = (1-norm.cdf((z)))\n",
    "        return pd.Series([z, p_value],\n",
    "                         index=[\"Statistic\", \"p-value\"], name=\"Binomial Test\")\n",
    "    \n",
    "    def plot(self, file_name=None):\n",
    "    \n",
    "        # Re-add the time series index\n",
    "        r = pd.Series(self.actual, index=self.index)\n",
    "        q = pd.Series(self.forecast, index=self.index)\n",
    "\n",
    "        sns.set_context(\"paper\")\n",
    "        sns.set_style(\"whitegrid\", {\"font.family\": \"serif\", \"font.serif\": \"Computer Modern Roman\", \"text.usetex\": True})\n",
    "\n",
    "        # Hits\n",
    "        ax = r[r <= q].plot(color=\"red\", marker=\"o\", ls=\"None\", figsize=(20, 10))\n",
    "        for h in r[r <= q].index:\n",
    "            plt.axvline(h, color=\"black\", alpha=0.4, linewidth=1, zorder=0)\n",
    "\n",
    "        # Positive returns\n",
    "        r[q < r].plot(ax=ax, color=\"green\", marker=\"o\", ls=\"None\")\n",
    "\n",
    "        # Negative returns but no hit\n",
    "        r[(q <= r) & (r <= 0)].plot(ax=ax, color=\"orange\", marker=\"o\", ls=\"None\")\n",
    "\n",
    "        # VaR\n",
    "        q.plot(ax=ax, grid=False, color=\"black\", rot=0)\n",
    "\n",
    "        # Axes\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"Log Return\")\n",
    "        ax.yaxis.grid()\n",
    "\n",
    "        sns.despine()\n",
    "        if file_name is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(file_name, bbox_inches=\"tight\")\n",
    "        plt.close(\"all\")\n",
    "\n",
    "    def tick_loss(self, return_mean=True):\n",
    "        loss = (self.alpha - self.hit_series()) * (self.actual - self.forecast)\n",
    "        if return_mean:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def smooth_loss(self, delta=25, return_mean=True):\n",
    "        \"\"\"Gonzalez-Rivera, Lee and Mishra (2004)\"\"\"\n",
    "        loss = ((self.alpha - (1 + np.exp(delta*(self.actual - self.forecast)))**-1) * (self.actual - self.forecast))\n",
    "        if return_mean:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def quadratic_loss(self, return_mean=True):\n",
    "        \"\"\"Lopez (1999); Martens et al. (2009)\"\"\"\n",
    "        loss = (self.hit_series() * (1 + (self.actual - self.forecast)**2))\n",
    "        if return_mean:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def firm_loss(self, c=1, return_mean=True):\n",
    "        \"\"\"Sarma et al. (2003)\"\"\"\n",
    "        loss = (self.hit_series() * (1 + (self.actual - self.forecast)**2) - c*(1-self.hit_series()) * self.forecast)\n",
    "        if return_mean:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def lr_bt(self):\n",
    "        \"\"\"Likelihood ratio framework of Christoffersen (1998)\"\"\"\n",
    "        hits = self.hit_series()   # Hit series\n",
    "        tr = hits[1:] - hits[:-1]  # Sequence to find transitions\n",
    "\n",
    "        # Transitions: nij denotes state i is followed by state j nij times\n",
    "        n01, n10 = (tr == 1).sum(), (tr == -1).sum()\n",
    "        n11, n00 = (hits[1:][tr == 0] == 1).sum(), (hits[1:][tr == 0] == 0).sum()\n",
    "\n",
    "        # Times in the states\n",
    "        n0, n1 = n01 + n00, n10 + n11\n",
    "        n = n0 + n1\n",
    "\n",
    "        # Probabilities of the transitions from one state to another\n",
    "        p01, p11 = n01 / (n00 + n01), n11 / (n11 + n10)\n",
    "        p = n1 / n\n",
    "\n",
    "        if n1 > 0:\n",
    "            # Unconditional Coverage\n",
    "            uc_h0 = n0 * np.log(1 - self.alpha) + n1 * np.log(self.alpha)\n",
    "            uc_h1 = n0 * np.log(1 - p) + n1 * np.log(p)\n",
    "            uc = -2 * (uc_h0 - uc_h1)\n",
    "\n",
    "            # Independence\n",
    "            ind_h0 = (n00 + n01) * np.log(1 - p) + (n01 + n11) * np.log(p)\n",
    "            ind_h1 = n00 * np.log(1 - p01) + n01 * np.log(p01) + n10 * np.log(1 - p11)\n",
    "            if p11 > 0:\n",
    "                ind_h1 += n11 * np.log(p11)\n",
    "            ind = -2 * (ind_h0 - ind_h1)\n",
    "\n",
    "            # Conditional coverage\n",
    "            cc = uc + ind\n",
    "\n",
    "            # Stack results\n",
    "            df = pd.concat([pd.Series([uc, ind, cc]),\n",
    "                            pd.Series([1 - stats.chi2.cdf(uc, 1),\n",
    "                                       1 - stats.chi2.cdf(ind, 1),\n",
    "                                       1 - stats.chi2.cdf(cc, 2)])], axis=1)\n",
    "        else:\n",
    "            df = pd.DataFrame(np.zeros((3, 2))).replace(0, np.nan)\n",
    "\n",
    "        # Assign names\n",
    "        df.columns = [\"Statistic\", \"p-value\"]\n",
    "        df.index = [\"Unconditional\", \"Independence\", \"Conditional\"]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def dq_bt(self, hit_lags=4, forecast_lags=1):\n",
    "        \"\"\"Dynamic Quantile Test (Engle & Manganelli, 2004)\"\"\"\n",
    "        try:\n",
    "            hits = self.hit_series()\n",
    "            p, q, n = hit_lags, forecast_lags, hits.size\n",
    "            pq = max(p, q - 1)\n",
    "            y = hits[pq:] - self.alpha  # Dependent variable\n",
    "            x = np.zeros((n - pq, 1 + p + q))\n",
    "            x[:, 0] = 1  # Constant\n",
    "\n",
    "            for i in range(p):  # Lagged hits\n",
    "                x[:, 1 + i] = hits[pq-(i+1):-(i+1)]\n",
    "\n",
    "            for j in range(q):  # Actual + lagged VaR forecast\n",
    "                if j > 0:\n",
    "                    x[:, 1 + p + j] = self.forecast[pq-j:-j]\n",
    "                else:\n",
    "                    x[:, 1 + p + j] = self.forecast[pq:]\n",
    "\n",
    "            beta = np.dot(np.linalg.inv(np.dot(x.T, x)), np.dot(x.T, y))\n",
    "            lr_dq = np.dot(beta, np.dot(np.dot(x.T, x), beta)) / (self.alpha * (1-self.alpha))\n",
    "            p_dq = 1 - stats.chi2.cdf(lr_dq, 1+p+q)\n",
    "\n",
    "        except:\n",
    "            lr_dq, p_dq = np.nan, np.nan\n",
    "\n",
    "        return pd.Series([lr_dq, p_dq],\n",
    "                         index=[\"Statistic\", \"p-value\"], name=\"DQ\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "returns=pd.DataFrame(returns)\n",
    "\n",
    "\n",
    "VaR_empiric=pd.DataFrame(VaR_empiric)\n",
    "VaR_GARCH_n=pd.DataFrame(VaR_GARCH_n)\n",
    "VaR_GARCH_t=pd.DataFrame(VaR_GARCH_t)\n",
    "VaR_GARCH_n=pd.DataFrame(VaR_GARCH_n)\n",
    "VaR_normal=pd.DataFrame(VaR_normal)\n",
    "VaR_t=pd.DataFrame(VaR_t)\n",
    "\n",
    "date=pd.DataFrame(dates)\n",
    "results=pd.concat([date, returns, \n",
    "                  VaR_empiric,VaR_GARCH_n, VaR_GARCH_t, VaR_normal,VaR_t], axis=1)\n",
    "results.columns=['date','Return', 'VaR_Empiric','VaR_GARCH_n', 'VaR_GARCH_t', 'VaR_normal','VaR_t']\n",
    "results.set_index('date',inplace=True)\n",
    "results=results.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    bt = Backtest(actual=results['Return'], forecast=results['VaR_normal'], alpha=alpha)\n",
    "    bt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of hits\n",
    "   \n",
    "bt.number_of_hits()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit rate\n",
    "bt.hit_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Christophersen Test\n",
    "bt.lr_bt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binomial test\n",
    "bt.binomial_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author   : John Tsang\n",
    "# Date     : December 7th, 2017\n",
    "# Purpose  : Implement the Diebold-Mariano Test (DM test) to compare \n",
    "#            forecast accuracy\n",
    "# Input    : 1) actual_lst: the list of actual values\n",
    "#            2) pred1_lst : the first list of predicted values\n",
    "#            3) pred2_lst : the second list of predicted values\n",
    "#            4) h         : the number of stpes ahead\n",
    "#            5) crit      : a string specifying the criterion \n",
    "#                             i)  MSE : the mean squared error\n",
    "#                            ii)  MAD : the mean absolute deviation\n",
    "#                           iii) MAPE : the mean absolute percentage error\n",
    "#                            iv) poly : use power function to weigh the errors\n",
    "#            6) poly      : the power for crit power \n",
    "#                           (it is only meaningful when crit is \"poly\")\n",
    "# Condition: 1) length of actual_lst, pred1_lst and pred2_lst is equal\n",
    "#            2) h must be an integer and it must be greater than 0 and less than \n",
    "#               the length of actual_lst.\n",
    "#            3) crit must take the 4 values specified in Input\n",
    "#            4) Each value of actual_lst, pred1_lst and pred2_lst must\n",
    "#               be numerical values. Missing values will not be accepted.\n",
    "#            5) power must be a numerical value.\n",
    "# Return   : a named-tuple of 2 elements\n",
    "#            1) p_value : the p-value of the DM test\n",
    "#            2) DM      : the test statistics of the DM test\n",
    "##########################################################\n",
    "# References:\n",
    "#\n",
    "# Harvey, D., Leybourne, S., & Newbold, P. (1997). Testing the equality of \n",
    "#   prediction mean squared errors. International Journal of forecasting, \n",
    "#   13(2), 281-291.\n",
    "#\n",
    "# Diebold, F. X. and Mariano, R. S. (1995), Comparing predictive accuracy, \n",
    "#   Journal of business & economic statistics 13(3), 253-264.\n",
    "#\n",
    "##########################################################\n",
    "def dm_test(actual_lst, pred1_lst, pred2_lst, h = 1, crit=\"MSE\", power = 2):\n",
    "\n",
    "    # Import libraries\n",
    "    from scipy.stats import t\n",
    "    import collections\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Initialise lists\n",
    "    e1_lst = []\n",
    "    e2_lst = []\n",
    "    d_lst  = []\n",
    "    \n",
    "    # convert every value of the lists into real values\n",
    "    actual_lst = actual_lst.values.tolist()\n",
    "    pred1_lst = pred1_lst.values.tolist()\n",
    "    pred2_lst = pred2_lst.values.tolist()\n",
    "\n",
    "    # Length of lists (as real numbers)\n",
    "    T = float(len(actual_lst))\n",
    "    \n",
    "    # construct d according to crit\n",
    "    if (crit == \"MSE\"):\n",
    "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
    "            e1_lst.append((actual - p1)**2)\n",
    "            e2_lst.append((actual - p2)**2)\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)\n",
    "    elif (crit == \"MAD\"):\n",
    "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
    "            e1_lst.append(abs(actual - p1))\n",
    "            e2_lst.append(abs(actual - p2))\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)\n",
    "    elif (crit == \"MAPE\"):\n",
    "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
    "            e1_lst.append(abs((actual - p1)/actual))\n",
    "            e2_lst.append(abs((actual - p2)/actual))\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)\n",
    "    elif (crit == \"poly\"):\n",
    "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
    "            e1_lst.append(((actual - p1))**(power))\n",
    "            e2_lst.append(((actual - p2))**(power))\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)    \n",
    "    \n",
    "    # Mean of d        \n",
    "    mean_d = pd.Series(d_lst).mean()\n",
    "    \n",
    "    # Find autocovariance and construct DM test statistics\n",
    "    def autocovariance(Xi, N, k, Xs):\n",
    "        autoCov = 0\n",
    "        T = float(N)\n",
    "        for i in np.arange(0, N-k):\n",
    "              autoCov += ((Xi[i+k])-Xs)*(Xi[i]-Xs)\n",
    "        return (1/(T))*autoCov\n",
    "    gamma = []\n",
    "    for lag in range(0,h):\n",
    "        gamma.append(autocovariance(d_lst,len(d_lst),lag,mean_d)) # 0, 1, 2\n",
    "    V_d = (gamma[0] + 2*sum(gamma[1:]))/T\n",
    "    DM_stat=V_d**(-0.5)*mean_d\n",
    "    harvey_adj=((T+1-2*h+h*(h-1)/T)/T)**(0.5)\n",
    "    DM_stat = harvey_adj*DM_stat\n",
    "    # Find p-value\n",
    "    p_value = 2*t.cdf(-abs(DM_stat), df = T - 1)\n",
    "    \n",
    "    # Construct named tuple for return\n",
    "    dm_return = collections.namedtuple('dm_return', 'DM p_value')\n",
    "    \n",
    "    rt = dm_return(DM = DM_stat, p_value = p_value)\n",
    "    \n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = dm_test(results['Return'], \n",
    "             results['VaR_GARCH_t'],\n",
    "              results['VaR_Empiric'],h = 1, crit=\"MSE\")\n",
    "print (rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecasting\n",
    "ret=log_returns[-w:]\n",
    "\n",
    "mu=ret.mean()\n",
    "\n",
    "# define model\n",
    "model = arch_model(ret*100, vol='GARCH', p=1, q=1,dist='StudentsT');\n",
    "# fit model\n",
    "model_fit = model.fit(disp=0);\n",
    "df=(model_fit.params[4]);\n",
    "# forecast the test set\n",
    "yhat = model_fit.forecast(horizon=1);\n",
    "var_t=0.01*np.sqrt(yhat.variance.values[-1]) * t.ppf(alpha,df)  +mu;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VaR pentru 10 Nov 2020\n",
    "print(-var_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VaR pentru 13 Nov 2020\n",
    "var_t=0.01*np.sqrt(yhat.variance.values[-1]) *np.sqrt(4)* t.ppf(alpha,df)  +mu;\n",
    "print(-var_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaR Normal pentru 10 Nov 2020\n",
    "sigma=ret.std()\n",
    "v_normal=norm.ppf(alpha, mu, sigma);\n",
    "print(-v_normal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
